{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "random_state = 10 # Ensure reproducible results\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbed_mat = loadmat('Queries/suggestion_testbed.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3728"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testbed_mat['trainingIndexes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "508"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testbed_mat['missingIngs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "508"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testbed_mat['supports'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 60,  88, 182, 261, 269, 565, 586]),)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(testbed_mat['antecedents'][0]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  4],\n",
       "       [  3],\n",
       "       [ 11],\n",
       "       [  3],\n",
       "       [  9],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  4],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  7],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [ 10],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  5],\n",
       "       [  8],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  5],\n",
       "       [  3],\n",
       "       [ 17],\n",
       "       [  6],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [ 10],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  6],\n",
       "       [  7],\n",
       "       [ 11],\n",
       "       [  3],\n",
       "       [  8],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  7],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  5],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [ 13],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [  3],\n",
       "       [  4],\n",
       "       [  3],\n",
       "       [  6],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  6],\n",
       "       [  7],\n",
       "       [  4],\n",
       "       [  3],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  4],\n",
       "       [  6],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  4],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  9],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  6],\n",
       "       [ 13],\n",
       "       [  2],\n",
       "       [ 45],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  4],\n",
       "       [  4],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  5],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  5],\n",
       "       [  3],\n",
       "       [ 33],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  4],\n",
       "       [ 56],\n",
       "       [ 12],\n",
       "       [  3],\n",
       "       [  5],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  7],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [ 14],\n",
       "       [105],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  8],\n",
       "       [  4],\n",
       "       [  6],\n",
       "       [  2],\n",
       "       [  6],\n",
       "       [  7],\n",
       "       [  6],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [ 13],\n",
       "       [  4],\n",
       "       [  5],\n",
       "       [  4],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [  5],\n",
       "       [  6],\n",
       "       [ 19],\n",
       "       [  4],\n",
       "       [  4],\n",
       "       [  3],\n",
       "       [ 21],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [ 18],\n",
       "       [  5],\n",
       "       [  6],\n",
       "       [  6],\n",
       "       [  2],\n",
       "       [  9],\n",
       "       [  9],\n",
       "       [  3],\n",
       "       [ 33],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  5],\n",
       "       [  3],\n",
       "       [  4],\n",
       "       [  7],\n",
       "       [  5],\n",
       "       [  5],\n",
       "       [  6],\n",
       "       [  2],\n",
       "       [ 16],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  7],\n",
       "       [  6],\n",
       "       [  3],\n",
       "       [ 15],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [ 10],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [  3],\n",
       "       [  5],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [ 10],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [ 19],\n",
       "       [  5],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  5],\n",
       "       [  2],\n",
       "       [ 38],\n",
       "       [  7],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  4],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [ 13],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  8],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  9],\n",
       "       [  2],\n",
       "       [ 10],\n",
       "       [  2],\n",
       "       [  6],\n",
       "       [  2],\n",
       "       [ 16],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  7],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  5],\n",
       "       [ 18],\n",
       "       [  8],\n",
       "       [  6],\n",
       "       [  2],\n",
       "       [  5],\n",
       "       [ 11],\n",
       "       [ 11],\n",
       "       [  5],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  5],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  5],\n",
       "       [  4],\n",
       "       [  7],\n",
       "       [  4],\n",
       "       [  7],\n",
       "       [ 19],\n",
       "       [  6],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  4],\n",
       "       [  4],\n",
       "       [  3],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [  5],\n",
       "       [  4],\n",
       "       [ 11],\n",
       "       [  4],\n",
       "       [ 94],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [  5],\n",
       "       [  9],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [  4],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  9],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  8],\n",
       "       [  8],\n",
       "       [  4],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [ 11],\n",
       "       [  9],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [ 11],\n",
       "       [  6],\n",
       "       [  4],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [  7],\n",
       "       [  2],\n",
       "       [  5],\n",
       "       [  2],\n",
       "       [  7],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  5],\n",
       "       [  4],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  5],\n",
       "       [  3],\n",
       "       [  5],\n",
       "       [  4],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  7],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  8],\n",
       "       [  2],\n",
       "       [  6],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  6],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  5],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  6],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [ 20],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  6],\n",
       "       [ 10],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  7],\n",
       "       [  3],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  6],\n",
       "       [ 12],\n",
       "       [  3],\n",
       "       [ 15],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [ 12],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  8],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  5],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [ 81],\n",
       "       [  2],\n",
       "       [  5],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  4],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  8],\n",
       "       [  2],\n",
       "       [  5],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  4],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  5],\n",
       "       [  5],\n",
       "       [ 10],\n",
       "       [  6],\n",
       "       [  7],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  2],\n",
       "       [  8],\n",
       "       [  5],\n",
       "       [  2],\n",
       "       [  2],\n",
       "       [  3],\n",
       "       [  9]], dtype=uint8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testbed_mat['supports']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "508"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testbed_mat['froms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   3],\n",
       "       [   7],\n",
       "       [  11],\n",
       "       [  14],\n",
       "       [  36],\n",
       "       [  40],\n",
       "       [  47],\n",
       "       [  52],\n",
       "       [  59],\n",
       "       [  65],\n",
       "       [  67],\n",
       "       [  72],\n",
       "       [  73],\n",
       "       [  84],\n",
       "       [  90],\n",
       "       [ 112],\n",
       "       [ 157],\n",
       "       [ 166],\n",
       "       [ 176],\n",
       "       [ 181],\n",
       "       [ 192],\n",
       "       [ 213],\n",
       "       [ 240],\n",
       "       [ 253],\n",
       "       [ 264],\n",
       "       [ 268],\n",
       "       [ 277],\n",
       "       [ 281],\n",
       "       [ 297],\n",
       "       [ 298],\n",
       "       [ 335],\n",
       "       [ 343],\n",
       "       [ 362],\n",
       "       [ 366],\n",
       "       [ 381],\n",
       "       [ 384],\n",
       "       [ 387],\n",
       "       [ 408],\n",
       "       [ 429],\n",
       "       [ 441],\n",
       "       [ 442],\n",
       "       [ 445],\n",
       "       [ 450],\n",
       "       [ 452],\n",
       "       [ 462],\n",
       "       [ 474],\n",
       "       [ 505],\n",
       "       [ 510],\n",
       "       [ 526],\n",
       "       [ 537],\n",
       "       [ 538],\n",
       "       [ 543],\n",
       "       [ 557],\n",
       "       [ 561],\n",
       "       [ 564],\n",
       "       [ 584],\n",
       "       [ 585],\n",
       "       [ 597],\n",
       "       [ 599],\n",
       "       [ 600],\n",
       "       [ 601],\n",
       "       [ 603],\n",
       "       [ 622],\n",
       "       [ 631],\n",
       "       [ 644],\n",
       "       [ 656],\n",
       "       [ 665],\n",
       "       [ 696],\n",
       "       [ 699],\n",
       "       [ 702],\n",
       "       [ 713],\n",
       "       [ 715],\n",
       "       [ 716],\n",
       "       [ 725],\n",
       "       [ 728],\n",
       "       [ 731],\n",
       "       [ 743],\n",
       "       [ 744],\n",
       "       [ 748],\n",
       "       [ 755],\n",
       "       [ 758],\n",
       "       [ 765],\n",
       "       [ 773],\n",
       "       [ 778],\n",
       "       [ 790],\n",
       "       [ 793],\n",
       "       [ 794],\n",
       "       [ 798],\n",
       "       [ 801],\n",
       "       [ 816],\n",
       "       [ 840],\n",
       "       [ 848],\n",
       "       [ 851],\n",
       "       [ 858],\n",
       "       [ 862],\n",
       "       [ 874],\n",
       "       [ 883],\n",
       "       [ 900],\n",
       "       [ 938],\n",
       "       [ 946],\n",
       "       [ 948],\n",
       "       [ 949],\n",
       "       [ 950],\n",
       "       [ 971],\n",
       "       [ 978],\n",
       "       [ 999],\n",
       "       [1005],\n",
       "       [1008],\n",
       "       [1018],\n",
       "       [1024],\n",
       "       [1026],\n",
       "       [1038],\n",
       "       [1050],\n",
       "       [1071],\n",
       "       [1073],\n",
       "       [1075],\n",
       "       [1077],\n",
       "       [1082],\n",
       "       [1085],\n",
       "       [1098],\n",
       "       [1099],\n",
       "       [1100],\n",
       "       [1115],\n",
       "       [1132],\n",
       "       [1145],\n",
       "       [1147],\n",
       "       [1161],\n",
       "       [1165],\n",
       "       [1166],\n",
       "       [1173],\n",
       "       [1177],\n",
       "       [1182],\n",
       "       [1185],\n",
       "       [1187],\n",
       "       [1192],\n",
       "       [1203],\n",
       "       [1231],\n",
       "       [1233],\n",
       "       [1239],\n",
       "       [1271],\n",
       "       [1274],\n",
       "       [1282],\n",
       "       [1286],\n",
       "       [1287],\n",
       "       [1300],\n",
       "       [1301],\n",
       "       [1312],\n",
       "       [1340],\n",
       "       [1342],\n",
       "       [1366],\n",
       "       [1387],\n",
       "       [1391],\n",
       "       [1397],\n",
       "       [1403],\n",
       "       [1409],\n",
       "       [1440],\n",
       "       [1442],\n",
       "       [1447],\n",
       "       [1453],\n",
       "       [1454],\n",
       "       [1457],\n",
       "       [1473],\n",
       "       [1474],\n",
       "       [1477],\n",
       "       [1479],\n",
       "       [1487],\n",
       "       [1493],\n",
       "       [1494],\n",
       "       [1505],\n",
       "       [1511],\n",
       "       [1514],\n",
       "       [1519],\n",
       "       [1533],\n",
       "       [1535],\n",
       "       [1546],\n",
       "       [1550],\n",
       "       [1553],\n",
       "       [1560],\n",
       "       [1571],\n",
       "       [1576],\n",
       "       [1577],\n",
       "       [1589],\n",
       "       [1590],\n",
       "       [1593],\n",
       "       [1595],\n",
       "       [1600],\n",
       "       [1624],\n",
       "       [1625],\n",
       "       [1626],\n",
       "       [1631],\n",
       "       [1634],\n",
       "       [1643],\n",
       "       [1647],\n",
       "       [1648],\n",
       "       [1658],\n",
       "       [1670],\n",
       "       [1676],\n",
       "       [1684],\n",
       "       [1690],\n",
       "       [1701],\n",
       "       [1709],\n",
       "       [1716],\n",
       "       [1728],\n",
       "       [1735],\n",
       "       [1742],\n",
       "       [1759],\n",
       "       [1763],\n",
       "       [1764],\n",
       "       [1781],\n",
       "       [1783],\n",
       "       [1804],\n",
       "       [1807],\n",
       "       [1814],\n",
       "       [1820],\n",
       "       [1822],\n",
       "       [1824],\n",
       "       [1873],\n",
       "       [1874],\n",
       "       [1891],\n",
       "       [1967],\n",
       "       [1972],\n",
       "       [2016],\n",
       "       [2031],\n",
       "       [2051],\n",
       "       [2065],\n",
       "       [2076],\n",
       "       [2088],\n",
       "       [2090],\n",
       "       [2115],\n",
       "       [2127],\n",
       "       [2131],\n",
       "       [2137],\n",
       "       [2143],\n",
       "       [2148],\n",
       "       [2151],\n",
       "       [2158],\n",
       "       [2159],\n",
       "       [2161],\n",
       "       [2163],\n",
       "       [2164],\n",
       "       [2168],\n",
       "       [2169],\n",
       "       [2170],\n",
       "       [2172],\n",
       "       [2176],\n",
       "       [2177],\n",
       "       [2179],\n",
       "       [2180],\n",
       "       [2181],\n",
       "       [2182],\n",
       "       [2187],\n",
       "       [2188],\n",
       "       [2192],\n",
       "       [2197],\n",
       "       [2198],\n",
       "       [2200],\n",
       "       [2201],\n",
       "       [2205],\n",
       "       [2209],\n",
       "       [2210],\n",
       "       [2216],\n",
       "       [2217],\n",
       "       [2223],\n",
       "       [2231],\n",
       "       [2239],\n",
       "       [2242],\n",
       "       [2243],\n",
       "       [2244],\n",
       "       [2257],\n",
       "       [2259],\n",
       "       [2260],\n",
       "       [2262],\n",
       "       [2266],\n",
       "       [2270],\n",
       "       [2281],\n",
       "       [2284],\n",
       "       [2296],\n",
       "       [2302],\n",
       "       [2307],\n",
       "       [2312],\n",
       "       [2316],\n",
       "       [2321],\n",
       "       [2322],\n",
       "       [2323],\n",
       "       [2327],\n",
       "       [2338],\n",
       "       [2341],\n",
       "       [2350],\n",
       "       [2352],\n",
       "       [2356],\n",
       "       [2357],\n",
       "       [2362],\n",
       "       [2368],\n",
       "       [2375],\n",
       "       [2379],\n",
       "       [2382],\n",
       "       [2395],\n",
       "       [2397],\n",
       "       [2416],\n",
       "       [2425],\n",
       "       [2428],\n",
       "       [2442],\n",
       "       [2447],\n",
       "       [2448],\n",
       "       [2454],\n",
       "       [2456],\n",
       "       [2460],\n",
       "       [2461],\n",
       "       [2476],\n",
       "       [2478],\n",
       "       [2482],\n",
       "       [2492],\n",
       "       [2494],\n",
       "       [2495],\n",
       "       [2505],\n",
       "       [2506],\n",
       "       [2508],\n",
       "       [2510],\n",
       "       [2513],\n",
       "       [2515],\n",
       "       [2522],\n",
       "       [2536],\n",
       "       [2542],\n",
       "       [2545],\n",
       "       [2546],\n",
       "       [2548],\n",
       "       [2554],\n",
       "       [2559],\n",
       "       [2561],\n",
       "       [2564],\n",
       "       [2572],\n",
       "       [2575],\n",
       "       [2576],\n",
       "       [2580],\n",
       "       [2587],\n",
       "       [2590],\n",
       "       [2599],\n",
       "       [2601],\n",
       "       [2606],\n",
       "       [2607],\n",
       "       [2614],\n",
       "       [2624],\n",
       "       [2649],\n",
       "       [2652],\n",
       "       [2653],\n",
       "       [2656],\n",
       "       [2665],\n",
       "       [2672],\n",
       "       [2683],\n",
       "       [2685],\n",
       "       [2686],\n",
       "       [2688],\n",
       "       [2692],\n",
       "       [2706],\n",
       "       [2713],\n",
       "       [2721],\n",
       "       [2732],\n",
       "       [2758],\n",
       "       [2759],\n",
       "       [2761],\n",
       "       [2766],\n",
       "       [2767],\n",
       "       [2771],\n",
       "       [2775],\n",
       "       [2788],\n",
       "       [2794],\n",
       "       [2796],\n",
       "       [2800],\n",
       "       [2802],\n",
       "       [2811],\n",
       "       [2834],\n",
       "       [2843],\n",
       "       [2844],\n",
       "       [2850],\n",
       "       [2851],\n",
       "       [2853],\n",
       "       [2856],\n",
       "       [2861],\n",
       "       [2866],\n",
       "       [2872],\n",
       "       [2901],\n",
       "       [2909],\n",
       "       [2919],\n",
       "       [2926],\n",
       "       [2935],\n",
       "       [2938],\n",
       "       [2950],\n",
       "       [2954],\n",
       "       [2959],\n",
       "       [2970],\n",
       "       [2972],\n",
       "       [2978],\n",
       "       [2992],\n",
       "       [3002],\n",
       "       [3020],\n",
       "       [3024],\n",
       "       [3028],\n",
       "       [3046],\n",
       "       [3107],\n",
       "       [3160],\n",
       "       [3172],\n",
       "       [3177],\n",
       "       [3182],\n",
       "       [3196],\n",
       "       [3202],\n",
       "       [3205],\n",
       "       [3206],\n",
       "       [3207],\n",
       "       [3218],\n",
       "       [3227],\n",
       "       [3234],\n",
       "       [3237],\n",
       "       [3242],\n",
       "       [3244],\n",
       "       [3250],\n",
       "       [3252],\n",
       "       [3292],\n",
       "       [3302],\n",
       "       [3315],\n",
       "       [3326],\n",
       "       [3336],\n",
       "       [3341],\n",
       "       [3356],\n",
       "       [3370],\n",
       "       [3379],\n",
       "       [3390],\n",
       "       [3428],\n",
       "       [3454],\n",
       "       [3456],\n",
       "       [3466],\n",
       "       [3467],\n",
       "       [3472],\n",
       "       [3474],\n",
       "       [3482],\n",
       "       [3489],\n",
       "       [3495],\n",
       "       [3506],\n",
       "       [3512],\n",
       "       [3526],\n",
       "       [3530],\n",
       "       [3548],\n",
       "       [3551],\n",
       "       [3553],\n",
       "       [3554],\n",
       "       [3565],\n",
       "       [3578],\n",
       "       [3581],\n",
       "       [3604],\n",
       "       [3610],\n",
       "       [3617],\n",
       "       [3625],\n",
       "       [3629],\n",
       "       [3643],\n",
       "       [3648],\n",
       "       [3650],\n",
       "       [3654],\n",
       "       [3674],\n",
       "       [3683],\n",
       "       [3695],\n",
       "       [3711],\n",
       "       [3715],\n",
       "       [3726],\n",
       "       [3737],\n",
       "       [3771],\n",
       "       [3773],\n",
       "       [3776],\n",
       "       [3783],\n",
       "       [3787],\n",
       "       [3788],\n",
       "       [3792],\n",
       "       [3800],\n",
       "       [3806],\n",
       "       [3808],\n",
       "       [3811],\n",
       "       [3819],\n",
       "       [3826],\n",
       "       [3835],\n",
       "       [3846],\n",
       "       [3853],\n",
       "       [3857],\n",
       "       [3858],\n",
       "       [3863],\n",
       "       [3872],\n",
       "       [3874],\n",
       "       [3892],\n",
       "       [3925],\n",
       "       [3942],\n",
       "       [3948],\n",
       "       [3949],\n",
       "       [3950],\n",
       "       [3951],\n",
       "       [3956],\n",
       "       [3960],\n",
       "       [3968],\n",
       "       [3984],\n",
       "       [3995],\n",
       "       [4011],\n",
       "       [4052],\n",
       "       [4079],\n",
       "       [4094],\n",
       "       [4107],\n",
       "       [4126],\n",
       "       [4167],\n",
       "       [4187],\n",
       "       [4188],\n",
       "       [4211],\n",
       "       [4221],\n",
       "       [4235]], dtype=uint16)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testbed_mat['froms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ing_mat = loadmat('MATLAB/ingredients.mat')['ingredients']\n",
    "cityDist_mat = loadmat('MATLAB/citiesDistMat.mat')['citiesDistMat']\n",
    "labelName_mat = loadmat('MATLAB/labelNames.mat')['labelNames']\n",
    "labels_mat = loadmat('MATLAB/labels.mat')['labels']\n",
    "recipe_mat = loadmat('MATLAB/recipes.mat')['recipes']\n",
    "ing_headline = []\n",
    "for i in ing_mat[0]:\n",
    "    ing_headline.append(i[0])\n",
    "dataset_X = pd.DataFrame(recipe_mat,columns=ing_headline)\n",
    "dataset_y = pd.DataFrame(labels_mat,columns=['label'])\n",
    "X_train_full,X_test,y_train_full,y_test = train_test_split(dataset_X,dataset_y,test_size=0.2)\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train_full,y_train_full,test_size=0.25)\n",
    "X_train_len = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acorn squash</th>\n",
       "      <th>adobo</th>\n",
       "      <th>african birdseye chile pepper</th>\n",
       "      <th>ale</th>\n",
       "      <th>aleppo pepper</th>\n",
       "      <th>alfalfa sprouts</th>\n",
       "      <th>alfredo sauce</th>\n",
       "      <th>allspice</th>\n",
       "      <th>almond</th>\n",
       "      <th>almond butter</th>\n",
       "      <th>...</th>\n",
       "      <th>yams</th>\n",
       "      <th>yeast</th>\n",
       "      <th>yellow curry paste</th>\n",
       "      <th>yellow food coloring</th>\n",
       "      <th>yellow split pea</th>\n",
       "      <th>yellow squash</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>zaatar</th>\n",
       "      <th>zest</th>\n",
       "      <th>zucchini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4236 rows Ã— 709 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      acorn squash  adobo  african birdseye chile pepper  ale  aleppo pepper  \\\n",
       "0                0      0                              0    0              0   \n",
       "1                0      0                              0    0              0   \n",
       "2                0      0                              0    0              0   \n",
       "3                0      0                              0    0              0   \n",
       "4                0      0                              0    0              0   \n",
       "...            ...    ...                            ...  ...            ...   \n",
       "4231             0      0                              0    0              0   \n",
       "4232             0      0                              0    0              0   \n",
       "4233             0      0                              0    0              0   \n",
       "4234             0      0                              0    0              0   \n",
       "4235             0      0                              0    0              0   \n",
       "\n",
       "      alfalfa sprouts  alfredo sauce  allspice  almond  almond butter  ...  \\\n",
       "0                   0              0         0       0              0  ...   \n",
       "1                   0              0         0       0              0  ...   \n",
       "2                   0              0         0       0              0  ...   \n",
       "3                   0              0         0       0              0  ...   \n",
       "4                   0              0         0       0              0  ...   \n",
       "...               ...            ...       ...     ...            ...  ...   \n",
       "4231                0              0         0       0              0  ...   \n",
       "4232                0              0         0       0              0  ...   \n",
       "4233                0              0         0       0              0  ...   \n",
       "4234                0              0         0       0              0  ...   \n",
       "4235                0              0         0       0              0  ...   \n",
       "\n",
       "      yams  yeast  yellow curry paste  yellow food coloring  yellow split pea  \\\n",
       "0        0      0                   0                     0                 0   \n",
       "1        0      0                   0                     0                 0   \n",
       "2        0      0                   0                     0                 0   \n",
       "3        0      0                   0                     0                 0   \n",
       "4        0      0                   0                     0                 0   \n",
       "...    ...    ...                 ...                   ...               ...   \n",
       "4231     0      0                   0                     0                 0   \n",
       "4232     0      0                   0                     0                 0   \n",
       "4233     0      0                   0                     0                 0   \n",
       "4234     0      0                   0                     0                 0   \n",
       "4235     0      0                   0                     0                 0   \n",
       "\n",
       "      yellow squash  yogurt  zaatar  zest  zucchini  \n",
       "0                 0       0       0     0         0  \n",
       "1                 0       0       0     0         0  \n",
       "2                 0       0       0     0         0  \n",
       "3                 0       0       0     0         0  \n",
       "4                 0       0       0     0         0  \n",
       "...             ...     ...     ...   ...       ...  \n",
       "4231              0       0       0     0         0  \n",
       "4232              0       0       0     0         0  \n",
       "4233              0       0       0     0         0  \n",
       "4234              0       0       0     0         0  \n",
       "4235              0       0       0     0         0  \n",
       "\n",
       "[4236 rows x 709 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_labels=None):\n",
    "    \"\"\"Plots a confusion matrix using seaborn's heatmap function\n",
    "    \n",
    "    Columns and rows are labelled with the strings provided in class_labels.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cm: array-like\n",
    "        contains the confusion matrix\n",
    "        \n",
    "    class_labels: array-like, optional\n",
    "        contains the string labels\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    # check whether we have count data or not\n",
    "    if issubclass(cm.dtype.type, np.integer):\n",
    "        fmt = 'd'\n",
    "    else:\n",
    "        fmt = '.2f'\n",
    "    \n",
    "    # Your code goes here\n",
    "    \n",
    "    if class_labels is not None:\n",
    "        sns.heatmap(cm, cmap='viridis',xticklabels=class_labels, yticklabels=class_labels,\\\n",
    "                    annot=True, annot_kws={\"fontsize\":9},  fmt=fmt)  # controls the display of the numbers\n",
    "    else:\n",
    "        sns.heatmap(cm, annot=True, annot_kws={\"fontsize\":9},  fmt=fmt)\n",
    "        \n",
    "    plt.ylabel('True label', fontweight='bold')\n",
    "    plt.xlabel('Predicted label', fontweight='bold')\n",
    "    \n",
    "    # you can change the appearance of the figure with lower-level matplotlib commands\n",
    "    # here we rotate the labels on the x-axis\n",
    "    plt.setp(plt.gca().get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy on the validation set:\n",
      "'Most-frequent' dummy classifier: 0.079\n",
      "'Stratified' dummy classifier: 0.072\n",
      "'prior' dummy classifier: 0.079\n",
      "'uniform' dummy classifier: 0.079\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Your code goes here\n",
    "\n",
    "def dummy_pipe(X_train, y_train, dummy_strategy):\n",
    "    \n",
    "    # dummy classifier\n",
    "    dclf = DummyClassifier(strategy=dummy_strategy)\n",
    "    \n",
    "    # construct the pipeline\n",
    "#     pipe = Pipeline([('scaler', StandardScaler()), ('dclf', dclf)])\n",
    "    pipe = Pipeline([('dclf', dclf)])\n",
    "    # train\n",
    "    pipe.fit(X_train, y_train)  # we do not need the _sc variable\n",
    "\n",
    "    return pipe\n",
    "\n",
    "pipe_mf = dummy_pipe(X_train, y_train, 'most_frequent')\n",
    "val_score_mf = pipe_mf.score(X_val, y_val)\n",
    "\n",
    "# Note: since labels are guessed randomly, different runs give different results\n",
    "pipe_strat = dummy_pipe(X_train, y_train, 'stratified')  \n",
    "val_score_strat = pipe_strat.score(X_val, y_val)\n",
    "\n",
    "#\n",
    "pipe_prior = dummy_pipe(X_train, y_train, 'prior')\n",
    "val_score_prior = pipe_mf.score(X_val, y_val)\n",
    "\n",
    "pipe_uni = dummy_pipe(X_train, y_train,'uniform')\n",
    "val_score_uni = pipe_mf.score(X_val, y_val)\n",
    "\n",
    "\n",
    "print(\"Classification accuracy on the validation set:\")\n",
    "print(\"'Most-frequent' dummy classifier: {0:.3f}\".format(val_score_mf))\n",
    "print(\"'Stratified' dummy classifier: {0:.3f}\".format(val_score_strat))\n",
    "print(\"'prior' dummy classifier: {0:.3f}\".format(val_score_prior))\n",
    "print(\"'uniform' dummy classifier: {0:.3f}\".format(val_score_uni))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GaussianNB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-6989c3361ec7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m classifiers = [\n\u001b[1;32m     13\u001b[0m     \u001b[0mDummyClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'most_frequent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GaussianNB' is not defined"
     ]
    }
   ],
   "source": [
    "# standardisation\n",
    "# sc = StandardScaler().fit(X_train)\n",
    "# X_train_sc = sc.transform(X_train)\n",
    "# X_val_sc = sc.transform(X_val)\n",
    "# X_test_sc = sc.transform(X_test)  # needed below\n",
    "X_train_sc = X_train\n",
    "X_val_sc = X_val\n",
    "names = [\"Dummy, most frequent\", \"Gaussian Naive Bayes\", \"Logistic Regression\",\n",
    "         \"Nearest Neighb (10)\", \"Nearest Neighb (5)\",\n",
    "         \"Linear SVM\", \"RBF SVM\",\n",
    "         \"Random Forest\", \"MLP\", \"MLP stronger reg\", \"LDA\", \"QDA\"]\n",
    "classifiers = [\n",
    "    DummyClassifier(strategy='most_frequent'),\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    KNeighborsClassifier(n_neighbors=10),\n",
    "    KNeighborsClassifier(n_neighbors=5), \n",
    "    SVC(kernel=\"linear\", probability=True, random_state=random_state),\n",
    "    SVC(kernel='rbf', probability=True, random_state=random_state),\n",
    "    RandomForestClassifier(max_depth=10, n_estimators=50,random_state=random_state),\n",
    "    MLPClassifier(random_state=random_state, max_iter=800),  # default regularisation\n",
    "    MLPClassifier(random_state=random_state, max_iter=800, alpha=1),  # more regularisation\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "# Training \n",
    "ca_train_score = {}  # Classification accuracy\n",
    "ce_train_score = {}  # Cross-entropy\n",
    "\n",
    "# Validation\n",
    "ca_val_score = {} \n",
    "ce_val_score = {}\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train_sc, y_train)\n",
    "    \n",
    "    ca_train_score[name] = clf.score(X_train_sc, y_train)\n",
    "    ce_train_score[name] = log_loss(y_train, clf.predict_proba(X_train_sc))\n",
    "    \n",
    "    ca_val_score[name] = clf.score(X_val_sc, y_val)\n",
    "    ce_val_score[name] = log_loss(y_val, clf.predict_proba(X_val_sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Classification performance on validation set: \\n')\n",
    "print(\"{0:<20s}   {1:-^25s}   {2:-^21s}\".format('','Validation', 'Training'))\n",
    "print(\"{0:<20s}{1:>13s}{2:>13s}{3:>13s}{4:>13s}\".format(\n",
    "    'Method', 'Accuracy\\u2191', 'Log-loss\\u2193',\n",
    "    'Accuracy\\u2191', 'Log-loss\\u2193'))\n",
    "print(\"-\"*(20+4*13))\n",
    "for clf in names:\n",
    "    print (\"{method:<20s}{val_accuracy:>13.3f}{val_logloss:>13.3f}{train_accuracy:>13.3f}{train_logloss:>13.3f}\".format(\n",
    "        method=clf, val_accuracy=ca_val_score[clf], val_logloss=ce_val_score[clf],\n",
    "        train_accuracy=ca_train_score[clf], train_logloss=ce_train_score[clf]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick random forest\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_full, y_train_full)\n",
    "ca_rf_test = clf.score(X_test, y_test)\n",
    "ce_rf_test = log_loss(y_test, clf.predict_proba(X_test))\n",
    "\n",
    "print(\"Performance on the test set\")\n",
    "print(\"Classification accuracy:\", ca_rf_test)\n",
    "print(\"Log-loss:\", ce_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = torch.tensor(X_train.to_numpy())\n",
    "train_y = torch.tensor(y_train.to_numpy())\n",
    "\n",
    "# Hyper parameters\n",
    "\n",
    "num_epochs = 35\n",
    "num_classes = 2\n",
    "batch_size = 25\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4236"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recipe_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4236"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recipe_mat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "710"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = np.concatenate((recipe_mat,labels_mat),axis=1)\n",
    "len(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_full = np.concatenate((recipe_mat,labels_mat),axis=1)\n",
    "train_dataset,test_dataset = train_test_split(dataset_full,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# Hyper parameters\n",
    "num_epochs = 5\n",
    "num_classes = 12\n",
    "batch_size = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=12):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7*7*32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 709])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [16, 1, 5, 5], but got 2-dimensional input of size [50, 709] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-031265cd0a64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-8ef7ccdefeb8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [16, 1, 5, 5], but got 2-dimensional input of size [50, 709] instead"
     ]
    }
   ],
   "source": [
    "model = ConvNet(num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, d in enumerate(train_loader):\n",
    "        images = d[:,:-1]\n",
    "        labels = d[:,-1]\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "# Test the model\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for d in test_loader:\n",
    "        images = d[:,:-1]\n",
    "        labels = d[:,-1]\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
