{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import numpy as np\n",
    "# import torch\n",
    "# import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "# from torchvision import datasets, transforms\n",
    "# from torch import nn, optim\n",
    "import random\n",
    "random_state = 10 # Ensure reproducible results\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking_data (data):\n",
    "    masked_data = data.copy()\n",
    "    y = []\n",
    "    for i in range(len(data)):\n",
    "        indexs = np.where(masked_data[i]==1)[0]\n",
    "        random_index = random.randint(0,len(indexs)-1)\n",
    "        masked_data[i][indexs[random_index]] = 0\n",
    "        y.append(indexs[random_index])\n",
    "    return masked_data,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testbed_mat = loadmat('Queries/suggestion_testbed.mat')\n",
    "ing_mat = loadmat('MATLAB/ingredients.mat')['ingredients']\n",
    "cityDist_mat = loadmat('MATLAB/citiesDistMat.mat')['citiesDistMat']\n",
    "labelName_mat = loadmat('MATLAB/labelNames.mat')['labelNames']\n",
    "labels_mat = loadmat('MATLAB/labels.mat')['labels']\n",
    "recipe_mat = loadmat('MATLAB/recipes.mat')['recipes']\n",
    "ing_headline = []\n",
    "for i in ing_mat[0]:\n",
    "    ing_headline.append(i[0])\n",
    "ing_headline.append('label')\n",
    "dataset_X,dataset_y = masking_data(recipe_mat)\n",
    "dataset_X = np.concatenate([dataset_X,labels_mat],axis=1)\n",
    "dataset_X = pd.DataFrame(dataset_X,columns=ing_headline)\n",
    "dataset_y = pd.DataFrame(dataset_y,columns=['label'])\n",
    "X_train_full,X_test,y_train_full,y_test = train_test_split(dataset_X,dataset_y,test_size=0.2)\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train_full,y_train_full,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acorn squash                      1\n",
       "adobo                             3\n",
       "african birdseye chile pepper     3\n",
       "ale                               3\n",
       "aleppo pepper                     1\n",
       "                                 ..\n",
       "yellow squash                     4\n",
       "yogurt                           76\n",
       "zaatar                            1\n",
       "zest                             11\n",
       "zucchini                         71\n",
       "Length: 709, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[:,:-1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7ff0f6cfa650>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## -- Plot number of ingredients\n",
    "ax = sns.displot(np.sum(X_train.iloc[:,:-1],axis=1), bins=np.linspace(1,29,29)+1,kde=True)\n",
    "ax.set(xlabel=\"Number of Ingredients\", title=\"Recipe length distribution (with KDE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Top 20 ingredients'}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#--- top 10 most used ingredients\n",
    "fig, ax = plt.subplots()\n",
    "# sum up occurences of each ingredient\n",
    "freq_ing = X_train.iloc[:,:-1].sum()\n",
    "# filter for the 10 most frequent\n",
    "most_freq_ing = freq_ing.nlargest(20)\n",
    "ax.set_title(\"Top 20 ingredients\")\n",
    "most_freq_ing.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc = StandardScaler().fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01984189, -0.03438071, -0.03438071, ..., -0.06593805,\n",
       "        -0.16954333,  0.70706692],\n",
       "       [-0.01984189, -0.03438071, -0.03438071, ..., -0.06593805,\n",
       "        -0.16954333, -0.15740319],\n",
       "       [-0.01984189, -0.03438071, -0.03438071, ..., -0.06593805,\n",
       "        -0.16954333, -1.0218733 ],\n",
       "       ...,\n",
       "       [-0.01984189, -0.03438071, -0.03438071, ..., -0.06593805,\n",
       "        -0.16954333, -1.59818671],\n",
       "       [-0.01984189, -0.03438071, -0.03438071, ..., -0.06593805,\n",
       "        -0.16954333, -1.59818671],\n",
       "       [-0.01984189, -0.03438071, -0.03438071, ..., -0.06593805,\n",
       "        -0.16954333, -0.7337166 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_2d_label(X_2d, y, ax=None, s=2, alpha=0.5, lw=2):\n",
    "    \"\"\"Visualise a 2D embedding with corresponding labels.\n",
    "    \n",
    "    X_2d : ndarray, shape (n_samples,2)\n",
    "        Low-dimensional feature representation.\n",
    "    \n",
    "    y : ndarray, shape (n_samples,)\n",
    "        Labels corresponding to the entries in X_2d.\n",
    "        \n",
    "    ax : matplotlib axes.Axes \n",
    "         axes to plot on\n",
    "         \n",
    "    s : float\n",
    "        Marker size for scatter plot.\n",
    "    \n",
    "    alpha : float\n",
    "        Transparency for scatter plot.\n",
    "        \n",
    "    lw : float\n",
    "        Linewidth for scatter plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    targets = np.unique(y)  # extract unique labels\n",
    "    colors = sns.color_palette(n_colors=targets.size)\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "    # scatter plot    \n",
    "    for color, target in zip(colors, targets):\n",
    "        ax.scatter(X_2d[y == target, 0], X_2d[y == target, 1], color=color, label=target, s=s, alpha=alpha, lw=lw)\n",
    "    \n",
    "    # add legend\n",
    "    ax.legend(loc='center left', bbox_to_anchor=[1.01, 0.5], scatterpoints=3, frameon=False); # Add a legend outside the plot at specified point\n",
    "    \n",
    "    return ax\n",
    "\n",
    "def kde_2d_label(X_2d, y, ax=None):\n",
    "    \"\"\"Kernel density estimate in a 2D embedding with corresponding labels.\n",
    "    \n",
    "    X_2d : ndarray, shape (n_samples,2)\n",
    "        Data to plot\n",
    "    \n",
    "    y : ndarray, shape (n_samples,)\n",
    "        Labels corresponding to the entries in X_2d.\n",
    "        \n",
    "    ax : matplotlib axes.Axes \n",
    "         axes to plot on    \n",
    "    \"\"\"\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "    targets = np.unique(y)\n",
    "    palette_name = 'bright'\n",
    "    colors = sns.color_palette(palette_name, n_colors=targets.size)\n",
    "    lines = []\n",
    "    for color, target in zip(colors, targets):\n",
    "        sns.kdeplot(X_2d[y==target, 0], X_2d[y==target, 1], ax=ax, cmap=sns.dark_palette(color, as_cmap=True))\n",
    "        lines.append(mlines.Line2D([], [], color=color, label=target))  # dummy line for the legend\n",
    "    \n",
    "    # add legend\n",
    "    ax.legend(lines, targets, loc='center left', bbox_to_anchor=[1.01, 0.5], frameon=False) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01984189, -0.03438071, -0.03438071, ..., -0.06593805,\n",
       "        -0.16954333,  0.70706692],\n",
       "       [-0.01984189, -0.03438071, -0.03438071, ..., -0.06593805,\n",
       "        -0.16954333, -0.15740319],\n",
       "       [-0.01984189, -0.03438071, -0.03438071, ..., -0.06593805,\n",
       "        -0.16954333, -1.0218733 ],\n",
       "       ...,\n",
       "       [-0.01984189, -0.03438071, -0.03438071, ..., -0.06593805,\n",
       "        -0.16954333, -1.59818671],\n",
       "       [-0.01984189, -0.03438071, -0.03438071, ..., -0.06593805,\n",
       "        -0.16954333, -1.59818671],\n",
       "       [-0.01984189, -0.03438071, -0.03438071, ..., -0.06593805,\n",
       "        -0.16954333, -0.7337166 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-917a4b186352>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mX_kpca_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKernelPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcur_ax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mscatter_2d_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_kpca_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_ax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mcur_ax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{} kernel'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mcur_ax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-5d2069885410>\u001b[0m in \u001b[0;36mscatter_2d_label\u001b[0;34m(X_2d, y, ax, s, alpha, lw)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# scatter plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_2d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_2d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# add legend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsoAAAKvCAYAAABzr+mpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjYUlEQVR4nO3dUYjl53nf8d9jbZVQ17FDtYEgyZFC13UWN2B3UFwCjYvdIulCukgJEpgkRVgkrUIgoaDi4gblyg1NIaA22VLjJhArSi7CQhRUmsgYTORqjB3FklHYKG60iqk2jqsbE8uiTy/muIzHz+78d/c/M9qdzwcG5pzzMud99+w+fPfMnDnV3QEAAL7Vm456AwAA8EYklAEAYCCUAQBgIJQBAGAglAEAYCCUAQBgsG8oV9XHquqVqvrCRW6vqvqVqjpXVc9W1XvW3yYAS5nbAOtY8ozyx5PceYnb70pyavPxYJL/fPXbAuAqfDzmNsBV2zeUu/tTSf76EkvuTfLrvePpJG+rqu9da4MAXB5zG2AdJ1b4GjcneWnX5fOb6768d2FVPZidZy/y5je/+R++853vXOHuAQ7XZz/72b/q7pNHvY+rsGhum9nA9eJK5/YaobxYd59JciZJtra2ent7+zDvHmAVVfW/jnoPh8HMBq4XVzq31/itFy8nuXXX5Vs21wHwxmRuAyywRiifTfLjm1dRvzfJq939bT92AcAbhrkNsMC+P3pRVZ9I8r4kN1XV+ST/LsnfSpLu/tUkTyS5O8m5JF9L8i8OarMA7M/cBljHvqHc3ffvc3sn+Ver7QiAq2JuA6zDO/MBAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAYFEoV9WdVfVCVZ2rqoeH299eVU9V1eeq6tmqunv9rQKwhJkNsI59Q7mqbkjyaJK7kpxOcn9Vnd6z7N8meby7353kviT/ae2NArA/MxtgPUueUb4jybnufrG7X0vyWJJ796zpJN+1+fytSf5yvS0CcBnMbICVLAnlm5O8tOvy+c11u/1Ckg9W1fkkTyT5mekLVdWDVbVdVdsXLly4gu0CsA8zG2Ala72Y7/4kH+/uW5LcneQ3qurbvnZ3n+nure7eOnny5Ep3DcBlMrMBFlgSyi8nuXXX5Vs21+32QJLHk6S7/yjJdya5aY0NAnBZzGyAlSwJ5WeSnKqq26vqxuy88OPsnjV/keT9SVJVP5Cdoev7dACHz8wGWMm+odzdryd5KMmTSb6YnVdKP1dVj1TVPZtlP5/kQ1X1x0k+keQnu7sPatMAzMxsgPWcWLKou5/Izgs+dl/3kV2fP5/kh9fdGgBXwswGWId35gMAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAwaJQrqo7q+qFqjpXVQ9fZM2PVdXzVfVcVf3mutsEYCkzG2AdJ/ZbUFU3JHk0yT9Ncj7JM1V1truf37XmVJJ/k+SHu/urVfU9B7VhAC7OzAZYz5JnlO9Icq67X+zu15I8luTePWs+lOTR7v5qknT3K+tuE4CFzGyAlSwJ5ZuTvLTr8vnNdbu9I8k7qurTVfV0Vd05faGqerCqtqtq+8KFC1e2YwAuxcwGWMlaL+Y7keRUkvcluT/Jf6mqt+1d1N1nunuru7dOnjy50l0DcJnMbIAFloTyy0lu3XX5ls11u51Pcra7v9Hdf57kT7MzhAE4XGY2wEqWhPIzSU5V1e1VdWOS+5Kc3bPmd7PzzESq6qbsfFvvxfW2CcBCZjbASvYN5e5+PclDSZ5M8sUkj3f3c1X1SFXds1n2ZJKvVNXzSZ5K8q+7+ysHtWkAZmY2wHqqu4/kjre2tnp7e/tI7hvgalTVZ7t766j3cZjMbOBadqVz2zvzAQDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBgUShX1Z1V9UJVnauqhy+x7kerqqtqa70tAnA5zGyAdewbylV1Q5JHk9yV5HSS+6vq9LDuLUl+Nsln1t4kAMuY2QDrWfKM8h1JznX3i939WpLHktw7rPvFJB9N8jcr7g+Ay2NmA6xkSSjfnOSlXZfPb677/6rqPUlu7e7fu9QXqqoHq2q7qrYvXLhw2ZsFYF9mNsBKrvrFfFX1piS/nOTn91vb3We6e6u7t06ePHm1dw3AZTKzAZZbEsovJ7l11+VbNtd901uSvCvJJ6vqS0nem+SsF4cAHAkzG2AlS0L5mSSnqur2qroxyX1Jzn7zxu5+tbtv6u7buvu2JE8nuae7tw9kxwBcipkNsJJ9Q7m7X0/yUJInk3wxyePd/VxVPVJV9xz0BgFYzswGWM+JJYu6+4kkT+y57iMXWfu+q98WAFfKzAZYh3fmAwCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAIDBolCuqjur6oWqOldVDw+3/1xVPV9Vz1bVH1TV962/VQCWMLMB1rFvKFfVDUkeTXJXktNJ7q+q03uWfS7JVnf/YJLfSfLv194oAPszswHWs+QZ5TuSnOvuF7v7tSSPJbl394Lufqq7v7a5+HSSW9bdJgALmdkAK1kSyjcneWnX5fOb6y7mgSS/fzWbAuCKmdkAKzmx5herqg8m2UryIxe5/cEkDybJ29/+9jXvGoDLZGYDXNqSZ5RfTnLrrsu3bK77FlX1gSQfTnJPd399+kLdfaa7t7p76+TJk1eyXwAuzcwGWMmSUH4myamqur2qbkxyX5KzuxdU1buT/Fp2Bu4r628TgIXMbICV7BvK3f16koeSPJnki0ke7+7nquqRqrpns+yXkvydJL9dVZ+vqrMX+XIAHCAzG2A9i35GubufSPLEnus+suvzD6y8LwCukJkNsA7vzAcAAAOhDAAAA6EMAAADoQwAAAOhDAAAA6EMAAADoQwAAAOhDAAAA6EMAAADoQwAAAOhDAAAA6EMAAADoQwAAAOhDAAAA6EMAAADoQwAAAOhDAAAA6EMAAADoQwAAAOhDAAAA6EMAAADoQwAAAOhDAAAA6EMAAADoQwAAAOhDAAAA6EMAAADoQwAAAOhDAAAA6EMAAADoQwAAAOhDAAAA6EMAAADoQwAAAOhDAAAA6EMAAADoQwAAAOhDAAAA6EMAAADoQwAAAOhDAAAA6EMAAADoQwAAAOhDAAAA6EMAAADoQwAAAOhDAAAA6EMAAADoQwAAAOhDAAAA6EMAACDRaFcVXdW1QtVda6qHh5u/46q+q3N7Z+pqttW3ykAi5jZAOvYN5Sr6oYkjya5K8npJPdX1ek9yx5I8tXu/ntJ/mOSj669UQD2Z2YDrGfJM8p3JDnX3S9292tJHkty75419yb5b5vPfyfJ+6uq1tsmAAuZ2QArObFgzc1JXtp1+XySH7rYmu5+vapeTfJ3k/zV7kVV9WCSBzcXv15VX7iSTV/DbsqeP5NjwJmPh+N25r9/1Bu4BDN7Pcft73XizMfFcTzzFc3tJaG8mu4+k+RMklTVdndvHeb9HzVnPh6c+fpXVdtHvYfDYGY783HgzMfDlc7tJT968XKSW3ddvmVz3bimqk4keWuSr1zJhgC4KmY2wEqWhPIzSU5V1e1VdWOS+5Kc3bPmbJKf2Hz+z5P8YXf3etsEYCEzG2Al+/7oxebn1x5K8mSSG5J8rLufq6pHkmx399kk/zXJb1TVuSR/nZ3BvJ8zV7Hva5UzHw/OfP17w57XzF6VMx8Pznw8XNGZy5MIAADw7bwzHwAADIQyAAAMDjyUj+NbqS44889V1fNV9WxV/UFVfd9R7HNN+51517ofraquqmv619IsOW9V/djmcX6uqn7zsPe4tgV/r99eVU9V1ec2f7fvPop9rqmqPlZVr1zs9wfXjl/Z/Jk8W1XvOew9rs3MNrP3rLsuZnZibh+HuX0gM7u7D+wjOy8k+bMk35/kxiR/nOT0njX/Msmvbj6/L8lvHeSeDvpj4Zn/SZK/vfn8p4/DmTfr3pLkU0meTrJ11Ps+4Mf4VJLPJfnuzeXvOep9H8KZzyT56c3np5N86aj3vcK5/3GS9yT5wkVuvzvJ7yepJO9N8pmj3vMhPM5m9jE482bddTGzL+NxNrev8bl9EDP7oJ9RPo5vpbrvmbv7qe7+2ubi09n5PafXsiWPc5L8YpKPJvmbw9zcAVhy3g8lebS7v5ok3f3KIe9xbUvO3Em+a/P5W5P85SHu70B096ey81shLubeJL/eO55O8raq+t7D2d2BMLPN7N2ul5mdmNvHYm4fxMw+6FCe3kr15out6e7Xk3zzrVSvVUvOvNsD2fnfzbVs3zNvvr1xa3f/3mFu7IAseYzfkeQdVfXpqnq6qu48tN0djCVn/oUkH6yq80meSPIzh7O1I3W5/97f6MxsMzvJdTezE3M7MbeTK5jZh/oW1nyrqvpgkq0kP3LUezlIVfWmJL+c5CePeCuH6UR2vo33vuw8+/SpqvoH3f1/jnJTB+z+JB/v7v9QVf8oO7+n913d/X+PemOwBjP7umdum9vf5qCfUT6Ob6W65Mypqg8k+XCSe7r764e0t4Oy35nfkuRdST5ZVV/Kzs8Fnb2GXxyy5DE+n+Rsd3+ju/88yZ9mZwBfq5ac+YEkjydJd/9Rku9MctOh7O7oLPr3fg0xs83s5Pqb2Ym5nZjbyRXM7IMO5eP4Vqr7nrmq3p3k17IzcK/1n4FK9jlzd7/a3Td1923dfVt2fsbvnu7ePprtXrUlf69/NzvPSqSqbsrOt/RePMQ9rm3Jmf8iyfuTpKp+IDsD98Kh7vLwnU3y45tXUr83yavd/eWj3tRVMLPN7OtxZifmtrm94/Jn9iG8AvHu7Pyv7M+SfHhz3SPZ+UeX7Dwov53kXJL/meT7D3pPb4Az/48k/zvJ5zcfZ496zwd95j1rP5lr/xXU+z3GlZ1vXT6f5E+S3HfUez6EM59O8unsvLL680n+2VHveYUzfyLJl5N8IzvPNj2Q5KeS/NSux/nRzZ/Jn1zrf68XPs5mtpl9TX6Y29f/3D6Ime0trAEAYOCd+QAAYCCUAQBgIJQBAGAglAEAYCCUAQBgIJQBAGAglAEAYCCUAQBgIJQBAGAglAEAYCCUAQBgIJQBAGAglAEAYCCUAQBgIJQBAGAglAEAYCCUAQBgIJQBAGAglAEAYCCUAQBgIJQBAGAglAEAYCCUAQBgIJQBAGAglAEAYCCUAQBgIJQBAGAglAEAYCCUAQBgIJQBAGAglAEAYCCUAQBgIJQBAGAglAEAYCCUAQBgIJQBAGAglAEAYCCUAQBgIJQBAGCwbyhX1ceq6pWq+sJFbq+q+pWqOldVz1bVe9bfJgBLmdsA61jyjPLHk9x5idvvSnJq8/Fgkv989dsC4Cp8POY2wFXbN5S7+1NJ/voSS+5N8uu94+kkb6uq711rgwBcHnMbYB0nVvgaNyd5adfl85vrvrx3YVU9mJ1nL/LmN7/5H77zne9c4e4BDtdnP/vZv+ruk0e9j6uwaG6b2cD14krn9hqhvFh3n0lyJkm2trZ6e3v7MO8eYBVV9b+Oeg+HwcwGrhdXOrfX+K0XLye5ddflWzbXAfDGZG4DLLBGKJ9N8uObV1G/N8mr3f1tP3YBwBuGuQ2wwL4/elFVn0jyviQ3VdX5JP8uyd9Kku7+1SRPJLk7ybkkX0vyLw5qswDsz9wGWMe+odzd9+9zeyf5V6vtCICrYm4DrMM78wEAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAQCgDAMBAKAMAwEAoAwDAYFEoV9WdVfVCVZ2rqoeH299eVU9V1eeq6tmqunv9rQKwhJkNsI59Q7mqbkjyaJK7kpxOcn9Vnd6z7N8meby7353kviT/ae2NArA/MxtgPUueUb4jybnufrG7X0vyWJJ796zpJN+1+fytSf5yvS0CcBnMbICVnFiw5uYkL+26fD7JD+1Z8wtJ/ntV/UySNyf5wCq7A+BymdkAK1nrxXz3J/l4d9+S5O4kv1FV3/a1q+rBqtququ0LFy6sdNcAXCYzG2CBJaH8cpJbd12+ZXPdbg8keTxJuvuPknxnkpv2fqHuPtPdW929dfLkySvbMQCXYmYDrGRJKD+T5FRV3V5VN2bnhR9n96z5iyTvT5Kq+oHsDF1PPwAcPjMbYCX7hnJ3v57koSRPJvlidl4p/VxVPVJV92yW/XySD1XVHyf5RJKf7O4+qE0DMDOzAdaz5MV86e4nkjyx57qP7Pr8+SQ/vO7WALgSZjbAOrwzHwAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAwWhXJV3VlVL1TVuap6+CJrfqyqnq+q56rqN9fdJgBLmdkA6zix34KquiHJo0n+aZLzSZ6pqrPd/fyuNaeS/JskP9zdX62q7zmoDQNwcWY2wHqWPKN8R5Jz3f1id7+W5LEk9+5Z86Ekj3b3V5Oku19Zd5sALGRmA6xkSSjfnOSlXZfPb67b7R1J3lFVn66qp6vqzukLVdWDVbVdVdsXLly4sh0DcClmNsBK1nox34kkp5K8L8n9Sf5LVb1t76LuPtPdW929dfLkyZXuGoDLZGYDLLAklF9Ocuuuy7dsrtvtfJKz3f2N7v7zJH+anSEMwOEyswFWsiSUn0lyqqpur6obk9yX5OyeNb+bnWcmUlU3Zefbei+ut00AFjKzAVaybyh39+tJHkryZJIvJnm8u5+rqkeq6p7NsieTfKWqnk/yVJJ/3d1fOahNAzAzswHWU919JHe8tbXV29vbR3LfAFejqj7b3VtHvY/DZGYD17IrndvemQ8AAAZCGQAABkIZAAAGQhkAAAZCGQAABkIZAAAGQhkAAAZCGQAABkIZAAAGQhkAAAZCGQAABkIZAAAGQhkAAAZCGQAABkIZAAAGQhkAAAZCGQAABkIZAAAGQhkAAAZCGQAABkIZAAAGQhkAAAZCGQAABkIZAAAGQhkAAAZCGQAABkIZAAAGQhkAAAZCGQAABkIZAAAGQhkAAAZCGQAABkIZAAAGQhkAAAZCGQAABkIZAAAGQhkAAAZCGQAABkIZAAAGQhkAAAZCGQAABkIZAAAGQhkAAAZCGQAABkIZAAAGQhkAAAZCGQAABkIZAAAGQhkAAAZCGQAABotCuarurKoXqupcVT18iXU/WlVdVVvrbRGAy2FmA6xj31CuqhuSPJrkriSnk9xfVaeHdW9J8rNJPrP2JgFYxswGWM+SZ5TvSHKuu1/s7teSPJbk3mHdLyb5aJK/WXF/AFweMxtgJUtC+eYkL+26fH5z3f9XVe9Jcmt3/96lvlBVPVhV21W1feHChcveLAD7MrMBVnLVL+arqjcl+eUkP7/f2u4+091b3b118uTJq71rAC6TmQ2w3JJQfjnJrbsu37K57pvekuRdST5ZVV9K8t4kZ704BOBImNkAK1kSys8kOVVVt1fVjUnuS3L2mzd296vdfVN339bdtyV5Osk93b19IDsG4FLMbICV7BvK3f16koeSPJnki0ke7+7nquqRqrrnoDcIwHJmNsB6TixZ1N1PJHliz3Ufucja9139tgC4UmY2wDq8Mx8AAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADBaFclXdWVUvVNW5qnp4uP3nqur5qnq2qv6gqr5v/a0CsISZDbCOfUO5qm5I8miSu5KcTnJ/VZ3es+xzSba6+weT/E6Sf7/2RgHYn5kNsJ4lzyjfkeRcd7/Y3a8leSzJvbsXdPdT3f21zcWnk9yy7jYBWMjMBljJklC+OclLuy6f31x3MQ8k+f3phqp6sKq2q2r7woULy3cJwFJmNsBKVn0xX1V9MMlWkl+abu/uM9291d1bJ0+eXPOuAbhMZjbApZ1YsOblJLfuunzL5rpvUVUfSPLhJD/S3V9fZ3sAXCYzG2AlS55RfibJqaq6vapuTHJfkrO7F1TVu5P8WpJ7uvuV9bcJwEJmNsBK9g3l7n49yUNJnkzyxSSPd/dzVfVIVd2zWfZLSf5Okt+uqs9X1dmLfDkADpCZDbCeJT96ke5+IskTe677yK7PP7DyvgC4QmY2wDq8Mx8AAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMhDIAAAyEMgAADIQyAAAMFoVyVd1ZVS9U1bmqeni4/Tuq6rc2t3+mqm5bfacALGJmA6xj31CuqhuSPJrkriSnk9xfVaf3LHsgyVe7++8l+Y9JPrr2RgHYn5kNsJ4lzyjfkeRcd7/Y3a8leSzJvXvW3Jvkv20+/50k76+qWm+bACxkZgOs5MSCNTcneWnX5fNJfuhia7r79ap6NcnfTfJXuxdV1YNJHtxc/HpVfeFKNn0Nuyl7/kyOAWc+Ho7bmf/+UW/gEszs9Ry3v9eJMx8Xx/HMVzS3l4Tyarr7TJIzSVJV2929dZj3f9Sc+Xhw5utfVW0f9R4Og5ntzMeBMx8PVzq3l/zoxctJbt11+ZbNdeOaqjqR5K1JvnIlGwLgqpjZACtZEsrPJDlVVbdX1Y1J7ktyds+as0l+YvP5P0/yh93d620TgIXMbICV7PujF5ufX3soyZNJbkjyse5+rqoeSbLd3WeT/Nckv1FV55L8dXYG837OXMW+r1XOfDw48/XvDXteM3tVznw8OPPxcEVnLk8iAADAt/POfAAAMBDKAAAwOPBQPo5vpbrgzD9XVc9X1bNV9QdV9X1Hsc817XfmXet+tKq6qq7pX0uz5LxV9WObx/m5qvrNw97j2hb8vX57VT1VVZ/b/N2++yj2uaaq+lhVvXKx3x9cO35l82fybFW957D3uDYz28zes+66mNmJuX0c5vaBzOzuPrCP7LyQ5M+SfH+SG5P8cZLTe9b8yyS/uvn8viS/dZB7OuiPhWf+J0n+9ubznz4OZ96se0uSTyV5OsnWUe/7gB/jU0k+l+S7N5e/56j3fQhnPpPkpzefn07ypaPe9wrn/sdJ3pPkCxe5/e4kv5+kkrw3yWeOes+H8Dib2cfgzJt118XMvozH2dy+xuf2Qczsg35G+Ti+leq+Z+7up7r7a5uLT2fn95xey5Y8zknyi0k+muRvDnNzB2DJeT+U5NHu/mqSdPcrh7zHtS05cyf5rs3nb03yl4e4vwPR3Z/Kzm+FuJh7k/x673g6yduq6nsPZ3cHwsw2s3e7XmZ2Ym4fi7l9EDP7oEN5eivVmy+2prtfT/LNt1K9Vi05824PZOd/N9eyfc+8+fbGrd39e4e5sQOy5DF+R5J3VNWnq+rpqrrz0HZ3MJac+ReSfLCqzid5IsnPHM7WjtTl/nt/ozOzzewk193MTsztxNxOrmBmH+pbWPOtquqDSbaS/MhR7+UgVdWbkvxykp884q0cphPZ+Tbe+7Lz7NOnquofdPf/OcpNHbD7k3y8u/9DVf2j7Pye3nd19/896o3BGszs6565bW5/m4N+Rvk4vpXqkjOnqj6Q5MNJ7unurx/S3g7Kfmd+S5J3JflkVX0pOz8XdPYafnHIksf4fJKz3f2N7v7zJH+anQF8rVpy5geSPJ4k3f1HSb4zyU2Hsrujs+jf+zXEzDazk+tvZifmdmJuJ1cwsw86lI/jW6nue+aqeneSX8vOwL3WfwYq2efM3f1qd9/U3bd1923Z+Rm/e7p7+2i2e9WW/L3+3ew8K5Gquik739J78RD3uLYlZ/6LJO9Pkqr6gewM3AuHusvDdzbJj29eSf3eJK9295ePelNXwcw2s6/HmZ2Y2+b2jsuf2YfwCsS7s/O/sj9L8uHNdY9k5x9dsvOg/HaSc0n+Z5LvP+g9vQHO/D+S/O8kn998nD3qPR/0mfes/WSu/VdQ7/cYV3a+dfl8kj9Jct9R7/kQznw6yaez88rqzyf5Z0e95xXO/IkkX07yjew82/RAkp9K8lO7HudHN38mf3Kt/71e+Dib2Wb2Nflhbl//c/sgZra3sAYAgIF35gMAgIFQBgCAgVAGAICBUAYAgIFQBgCAgVAGAICBUAYAgMH/A4vd1ZN4GfMhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "# Your code goes here\n",
    "\n",
    "kernels = ['poly', 'rbf', 'cosine', 'sigmoid']\n",
    "fig, ax = plt.subplots(2,2,figsize=(12,12));\n",
    "\n",
    "for ii, kernel in enumerate(kernels):\n",
    "    X_kpca_2d = KernelPCA(n_components=2, kernel=kernel).fit_transform(X_train_sc)\n",
    "    cur_ax = ax[ii//2, ii%2]\n",
    "    scatter_2d_label(X_kpca_2d, y_train, ax=cur_ax)\n",
    "    cur_ax.set(title='{} kernel'.format(kernel))\n",
    "    cur_ax.legend().set_visible(False)\n",
    "\n",
    "ax[0, 0].set_ylabel('Principal component 2')\n",
    "ax[1, 0].set_ylabel('Principal component 2')\n",
    "\n",
    "ax[1, 0].set_xlabel('Principal component 1')\n",
    "ax[1, 1].set_xlabel('Principal component 1')\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=[1.01, 1.], scatterpoints=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy on the validation set:\n",
      "'Most-frequent' dummy classifier: 0.050\n",
      "'Stratified' dummy classifier: 0.009\n",
      "'prior' dummy classifier: 0.050\n",
      "'uniform' dummy classifier: 0.050\n"
     ]
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, class_labels=None):\n",
    "    \"\"\"Plots a confusion matrix using seaborn's heatmap function\n",
    "    \n",
    "    Columns and rows are labelled with the strings provided in class_labels.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cm: array-like\n",
    "        contains the confusion matrix\n",
    "        \n",
    "    class_labels: array-like, optional\n",
    "        contains the string labels\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    # check whether we have count data or not\n",
    "    if issubclass(cm.dtype.type, np.integer):\n",
    "        fmt = 'd'\n",
    "    else:\n",
    "        fmt = '.2f'\n",
    "    \n",
    "    # Your code goes here\n",
    "    \n",
    "    if class_labels is not None:\n",
    "        sns.heatmap(cm, cmap='viridis',xticklabels=class_labels, yticklabels=class_labels,\\\n",
    "                    annot=True, annot_kws={\"fontsize\":9},  fmt=fmt)  # controls the display of the numbers\n",
    "    else:\n",
    "        sns.heatmap(cm, annot=True, annot_kws={\"fontsize\":9},  fmt=fmt)\n",
    "        \n",
    "    plt.ylabel('True label', fontweight='bold')\n",
    "    plt.xlabel('Predicted label', fontweight='bold')\n",
    "    \n",
    "    # you can change the appearance of the figure with lower-level matplotlib commands\n",
    "    # here we rotate the labels on the x-axis\n",
    "    plt.setp(plt.gca().get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "\n",
    "# Your code goes here\n",
    "\n",
    "def dummy_pipe(X_train, y_train, dummy_strategy):\n",
    "    \n",
    "    # dummy classifier\n",
    "    dclf = DummyClassifier(strategy=dummy_strategy)\n",
    "    \n",
    "    # construct the pipeline\n",
    "#     pipe = Pipeline([('scaler', StandardScaler()), ('dclf', dclf)])\n",
    "    pipe = Pipeline([('dclf', dclf)])\n",
    "    # train\n",
    "    pipe.fit(X_train, y_train)  # we do not need the _sc variable\n",
    "\n",
    "    return pipe\n",
    "\n",
    "pipe_mf = dummy_pipe(X_train, y_train, 'most_frequent')\n",
    "val_score_mf = pipe_mf.score(X_val, y_val)\n",
    "\n",
    "# Note: since labels are guessed randomly, different runs give different results\n",
    "pipe_strat = dummy_pipe(X_train, y_train, 'stratified')  \n",
    "val_score_strat = pipe_strat.score(X_val, y_val)\n",
    "\n",
    "#\n",
    "pipe_prior = dummy_pipe(X_train, y_train, 'prior')\n",
    "val_score_prior = pipe_mf.score(X_val, y_val)\n",
    "\n",
    "pipe_uni = dummy_pipe(X_train, y_train,'uniform')\n",
    "val_score_uni = pipe_mf.score(X_val, y_val)\n",
    "\n",
    "\n",
    "print(\"Classification accuracy on the validation set:\")\n",
    "print(\"'Most-frequent' dummy classifier: {0:.3f}\".format(val_score_mf))\n",
    "print(\"'Stratified' dummy classifier: {0:.3f}\".format(val_score_strat))\n",
    "print(\"'prior' dummy classifier: {0:.3f}\".format(val_score_prior))\n",
    "print(\"'uniform' dummy classifier: {0:.3f}\".format(val_score_uni))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred contain different number of classes 220, 350. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [  5   8  16  17  19  34  36  39  46  48  52  53  55  60  61  64  69  73\n  78  79  81  85  88  90  91  94  99 102 108 110 111 112 113 114 118 119\n 121 122 128 133 134 136 138 140 141 142 143 145 146 147 153 155 156 158\n 159 160 163 166 168 172 174 176 182 184 189 192 195 196 200 201 202 203\n 204 205 210 212 213 214 216 219 223 237 238 242 245 250 251 254 260 261\n 264 265 268 269 275 291 304 305 311 312 318 319 331 333 342 344 345 348\n 351 353 354 355 357 358 359 361 374 376 383 385 388 393 394 403 406 408\n 410 411 416 420 421 422 425 426 428 438 440 441 442 444 445 448 449 450\n 451 458 466 470 472 488 489 490 496 498 510 513 519 521 524 528 529 530\n 533 535 540 541 542 543 545 550 551 562 563 564 565 567 568 572 577 578\n 579 584 586 598 602 609 614 615 617 620 621 626 635 637 640 642 644 645\n 647 651 653 654 664 667 670 671 672 676 677 678 680 683 685 687 688 694\n 695 697 705 708]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-abbfb8796f73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mca_val_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_sc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mce_val_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   2269\u001b[0m                              \"y_true: {2}\".format(transformed_labels.shape[1],\n\u001b[1;32m   2270\u001b[0m                                                   \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2271\u001b[0;31m                                                   lb.classes_))\n\u001b[0m\u001b[1;32m   2272\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2273\u001b[0m             raise ValueError('The number of classes in labels is different '\n",
      "\u001b[0;31mValueError\u001b[0m: y_true and y_pred contain different number of classes 220, 350. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [  5   8  16  17  19  34  36  39  46  48  52  53  55  60  61  64  69  73\n  78  79  81  85  88  90  91  94  99 102 108 110 111 112 113 114 118 119\n 121 122 128 133 134 136 138 140 141 142 143 145 146 147 153 155 156 158\n 159 160 163 166 168 172 174 176 182 184 189 192 195 196 200 201 202 203\n 204 205 210 212 213 214 216 219 223 237 238 242 245 250 251 254 260 261\n 264 265 268 269 275 291 304 305 311 312 318 319 331 333 342 344 345 348\n 351 353 354 355 357 358 359 361 374 376 383 385 388 393 394 403 406 408\n 410 411 416 420 421 422 425 426 428 438 440 441 442 444 445 448 449 450\n 451 458 466 470 472 488 489 490 496 498 510 513 519 521 524 528 529 530\n 533 535 540 541 542 543 545 550 551 562 563 564 565 567 568 572 577 578\n 579 584 586 598 602 609 614 615 617 620 621 626 635 637 640 642 644 645\n 647 651 653 654 664 667 670 671 672 676 677 678 680 683 685 687 688 694\n 695 697 705 708]"
     ]
    }
   ],
   "source": [
    "# standardisation\n",
    "# sc = StandardScaler().fit(X_train)\n",
    "# X_train_sc = sc.transform(X_train)\n",
    "# X_val_sc = sc.transform(X_val)\n",
    "# X_test_sc = sc.transform(X_test)  # needed below\n",
    "X_train_sc = X_train\n",
    "X_val_sc = X_val\n",
    "names = [\"Dummy, most frequent\", \"Gaussian Naive Bayes\", \"Logistic Regression\",\n",
    "         \"Nearest Neighb (10)\", \"Nearest Neighb (5)\",\n",
    "         \"Linear SVM\", \"RBF SVM\",\n",
    "         \"Random Forest\", \"MLP\", \"MLP stronger reg\", \"LDA\", \"QDA\"]\n",
    "classifiers = [\n",
    "    DummyClassifier(strategy='most_frequent'),\n",
    "    GaussianNB(),\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    KNeighborsClassifier(n_neighbors=10),\n",
    "    KNeighborsClassifier(n_neighbors=5), \n",
    "    SVC(kernel=\"linear\", probability=True, random_state=random_state),\n",
    "    SVC(kernel='rbf', probability=True, random_state=random_state),\n",
    "    RandomForestClassifier(max_depth=10, n_estimators=50,random_state=random_state),\n",
    "    MLPClassifier(random_state=random_state, max_iter=800),  # default regularisation\n",
    "    MLPClassifier(random_state=random_state, max_iter=800, alpha=1),  # more regularisation\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "# Training \n",
    "ca_train_score = {}  # Classification accuracy\n",
    "ce_train_score = {}  # Cross-entropy\n",
    "\n",
    "# Validation\n",
    "ca_val_score = {} \n",
    "ce_val_score = {}\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train_sc, y_train)\n",
    "    \n",
    "    ca_train_score[name] = clf.score(X_train_sc, y_train)\n",
    "    ce_train_score[name] = log_loss(y_train, clf.predict_proba(X_train_sc))\n",
    "    \n",
    "    ca_val_score[name] = clf.score(X_val_sc, y_val)\n",
    "    ce_val_score[name] = log_loss(y_val, clf.predict_proba(X_val_sc))\n",
    "\n",
    "\n",
    "print('Classification performance on validation set: \\n')\n",
    "print(\"{0:<20s}   {1:-^25s}   {2:-^21s}\".format('','Validation', 'Training'))\n",
    "print(\"{0:<20s}{1:>13s}{2:>13s}{3:>13s}{4:>13s}\".format(\n",
    "    'Method', 'Accuracy\\u2191', 'Log-loss\\u2193',\n",
    "    'Accuracy\\u2191', 'Log-loss\\u2193'))\n",
    "print(\"-\"*(20+4*13))\n",
    "for clf in names:\n",
    "    print (\"{method:<20s}{val_accuracy:>13.3f}{val_logloss:>13.3f}{train_accuracy:>13.3f}{train_logloss:>13.3f}\".format(\n",
    "        method=clf, val_accuracy=ca_val_score[clf], val_logloss=ce_val_score[clf],\n",
    "        train_accuracy=ca_train_score[clf], train_logloss=ce_train_score[clf]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8072276ba49e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset_full\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_full' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ming/miniconda2/envs/monitor/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d9103a66fcc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# pick random forest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mca_rf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mce_rf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1414\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1416\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    759\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                 \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"iprint\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gtol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             )\n\u001b[1;32m    763\u001b[0m             n_iter_i = _check_optimize_result(\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 618\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    619\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(x, *args)\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_multi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0m_multinomial_loss_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0m_multinomial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss_grad\u001b[0;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# pick random forest\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_full, y_train_full)\n",
    "ca_rf_test = clf.score(X_test, y_test)\n",
    "ce_rf_test = log_loss(y_test, clf.predict_proba(X_test))\n",
    "\n",
    "print(\"Performance on the test set\")\n",
    "print(\"Classification accuracy:\", ca_rf_test)\n",
    "print(\"Log-loss:\", ce_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acorn squash</th>\n",
       "      <th>adobo</th>\n",
       "      <th>african birdseye chile pepper</th>\n",
       "      <th>ale</th>\n",
       "      <th>aleppo pepper</th>\n",
       "      <th>alfalfa sprouts</th>\n",
       "      <th>alfredo sauce</th>\n",
       "      <th>allspice</th>\n",
       "      <th>almond</th>\n",
       "      <th>almond butter</th>\n",
       "      <th>...</th>\n",
       "      <th>yeast</th>\n",
       "      <th>yellow curry paste</th>\n",
       "      <th>yellow food coloring</th>\n",
       "      <th>yellow split pea</th>\n",
       "      <th>yellow squash</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>zaatar</th>\n",
       "      <th>zest</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2541 rows × 710 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      acorn squash  adobo  african birdseye chile pepper  ale  aleppo pepper  \\\n",
       "2961             0      0                              0    0              0   \n",
       "1872             0      0                              0    0              0   \n",
       "757              0      0                              0    0              0   \n",
       "1212             0      0                              0    0              0   \n",
       "3980             0      0                              0    0              0   \n",
       "...            ...    ...                            ...  ...            ...   \n",
       "669              0      0                              0    0              0   \n",
       "3221             0      0                              0    0              0   \n",
       "193              0      0                              0    0              0   \n",
       "222              0      0                              0    0              0   \n",
       "1355             0      0                              0    0              0   \n",
       "\n",
       "      alfalfa sprouts  alfredo sauce  allspice  almond  almond butter  ...  \\\n",
       "2961                0              0         0       0              0  ...   \n",
       "1872                0              0         0       0              0  ...   \n",
       "757                 0              0         0       0              0  ...   \n",
       "1212                0              0         0       0              0  ...   \n",
       "3980                0              0         0       0              0  ...   \n",
       "...               ...            ...       ...     ...            ...  ...   \n",
       "669                 0              0         0       0              0  ...   \n",
       "3221                0              0         1       0              0  ...   \n",
       "193                 0              0         0       0              0  ...   \n",
       "222                 0              0         0       0              0  ...   \n",
       "1355                0              0         0       0              0  ...   \n",
       "\n",
       "      yeast  yellow curry paste  yellow food coloring  yellow split pea  \\\n",
       "2961      0                   0                     0                 0   \n",
       "1872      0                   0                     0                 0   \n",
       "757       0                   0                     0                 0   \n",
       "1212      0                   0                     0                 0   \n",
       "3980      0                   0                     0                 0   \n",
       "...     ...                 ...                   ...               ...   \n",
       "669       0                   0                     0                 0   \n",
       "3221      0                   0                     0                 0   \n",
       "193       0                   0                     0                 0   \n",
       "222       0                   0                     0                 0   \n",
       "1355      0                   0                     0                 0   \n",
       "\n",
       "      yellow squash  yogurt  zaatar  zest  zucchini  label  \n",
       "2961              0       0       0     0         0      9  \n",
       "1872              0       1       0     0         0      6  \n",
       "757               0       0       0     0         0      3  \n",
       "1212              0       0       0     0         0      4  \n",
       "3980              0       0       0     0         0     12  \n",
       "...             ...     ...     ...   ...       ...    ...  \n",
       "669               0       0       0     0         0      2  \n",
       "3221              0       0       0     0         0     10  \n",
       "193               0       0       0     0         0      1  \n",
       "222               0       0       0     0         0      1  \n",
       "1355              0       0       0     0         0      4  \n",
       "\n",
       "[2541 rows x 710 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch mlp for multiclass classification\n",
    "from numpy import vstack\n",
    "from numpy import argmax\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Softmax\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    "import torch.nn\n",
    "# Hyper parameters\n",
    "\n",
    "dataset_full = np.concatenate((recipe_mat,labels_mat),axis=1)\n",
    "train_dataset,test_dataset = train_test_split(dataset_full,test_size=0.2)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# Hyper parameters\n",
    "num_epochs = 5\n",
    "num_classes = 12\n",
    "batch_size = 50\n",
    "learning_rate = 0.001\n",
    "num_feature = 709\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "class MulticlassClassification(nn.Module):\n",
    "    def __init__(self, num_feature, num_class):\n",
    "        super(MulticlassClassification, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_feature, 512)\n",
    "        self.layer_2 = nn.Linear(512, 128)\n",
    "        self.layer_3 = nn.Linear(128, 64)\n",
    "        self.layer_out = nn.Linear(64, num_class) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(128)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print (x)\n",
    "        x = self.layer_1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer_2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.uint8)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-2d640f0f354e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-65eb0739b6dc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Byte"
     ]
    }
   ],
   "source": [
    "model = MulticlassClassification(num_feature,num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, d in enumerate(train_loader):\n",
    "        images = d[:,:-1]\n",
    "        labels = d[:,-1]\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "# Test the model\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for d in test_loader:\n",
    "        images = d[:,:-1]\n",
    "        labels = d[:,-1]\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import IntProgress\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_full = np.concatenate((recipe_mat,labels_mat),axis=1)\n",
    "train_dataset,X_test = train_test_split(dataset_full,test_size=0.2)\n",
    "X_train,X_val = train_test_split(train_dataset,test_size=0.2)\n",
    "ing_headline = []\n",
    "for i in ing_mat[0]:\n",
    "    ing_headline.append(i[0])\n",
    "ing_headline.append('label')\n",
    "X_train = pd.DataFrame(X_train,columns=ing_headline)\n",
    "X_val = pd.DataFrame(X_val,columns=ing_headline)\n",
    "X_test = pd.DataFrame(X_test,columns=ing_headline)\n",
    "X_train = X_train.to_numpy()\n",
    "X_val = X_val.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_dataset = ClassifierDataset(X_train[:,:-1], X_train[-1])\n",
    "val_dataset = ClassifierDataset(X_val[:,:-1], X_train[-1])\n",
    "test_dataset = ClassifierDataset(X_test[:,:-1], X_test[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = []\n",
    "for _, t in train_dataset:\n",
    "    target_list.append(t)\n",
    "    \n",
    "target_list = torch.tensor(target_list)\n",
    "target_list = target_list[torch.randperm(len(target_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.0007\n",
    "NUM_FEATURES = 709\n",
    "NUM_CLASSES = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    ")\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=1)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassClassification(nn.Module):\n",
    "    def __init__(self, num_feature, num_class):\n",
    "        super(MulticlassClassification, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_feature, 512)\n",
    "        self.layer_2 = nn.Linear(512, 128)\n",
    "        self.layer_3 = nn.Linear(128, 64)\n",
    "        self.layer_out = nn.Linear(64, num_class) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(128)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.layer_2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MulticlassClassification(\n",
      "  (layer_1): Linear(in_features=709, out_features=512, bias=True)\n",
      "  (layer_2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (layer_3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (layer_out): Linear(in_features=64, out_features=12, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MulticlassClassification(num_feature = NUM_FEATURES, num_class=NUM_CLASSES)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
    "    \n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}\n",
    "loss_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-d6e0ff73cdf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Begin training.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# TRAINING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_epoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0munit_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0munit_scale\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_printer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdisplay_here\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/monitor/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mIProgress\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# #187 #451 #558 #872\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             raise ImportError(\n\u001b[0;32m--> 113\u001b[0;31m                 \u001b[0;34m\"IProgress not found. Please update jupyter and ipywidgets.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;34m\" See https://ipywidgets.readthedocs.io/en/stable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \"/user_install.html\")\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "print(\"Begin training.\")\n",
    "for e in tqdm(range(1, EPOCHS+1)):\n",
    "    \n",
    "    # TRAINING\n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "    model.train()\n",
    "    for X_train_batch, y_train_batch in train_loader:\n",
    "        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_train_pred = model(X_train_batch)\n",
    "        \n",
    "        train_loss = criterion(y_train_pred, y_train_batch)\n",
    "        train_acc = multi_acc(y_train_pred, y_train_batch)\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_epoch_loss += train_loss.item()\n",
    "        train_epoch_acc += train_acc.item()\n",
    "        \n",
    "        \n",
    "    # VALIDATION    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        val_epoch_loss = 0\n",
    "        val_epoch_acc = 0\n",
    "        \n",
    "        model.eval()\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "            \n",
    "            y_val_pred = model(X_val_batch)\n",
    "                        \n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "            val_acc = multi_acc(y_val_pred, y_val_batch)\n",
    "            \n",
    "            val_epoch_loss += val_loss.item()\n",
    "            val_epoch_acc += val_acc.item()\n",
    "    loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
    "    loss_stats['val'].append(val_epoch_loss/len(val_loader))\n",
    "    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
    "    accuracy_stats['val'].append(val_epoch_acc/len(val_loader))\n",
    "                              \n",
    "    \n",
    "    print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(val_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}| Val Acc: {val_epoch_acc/len(val_loader):.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_full = np.concatenate((recipe_mat,labels_mat),axis=1)\n",
    "train_dataset,test_dataset = train_test_split(dataset_full,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
