{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- load required packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import loadmat\n",
    "\n",
    "#--- for reproducability\n",
    "random_state = 0\n",
    "\n",
    "#--- load data\n",
    "ing_mat = loadmat('MATLAB/ingredients.mat')['ingredients']\n",
    "cityDist_mat = loadmat('MATLAB/citiesDistMat.mat')['citiesDistMat']\n",
    "labelName_mat = loadmat('MATLAB/labelNames.mat')['labelNames']\n",
    "labels_mat = loadmat('MATLAB/labels.mat')['labels']\n",
    "recipe_mat = loadmat('MATLAB/recipes.mat')['recipes']\n",
    "\n",
    "#--- for colnames\n",
    "ing_headline = []\n",
    "for i in ing_mat[0]:\n",
    "    ing_headline.append(i[0])\n",
    "#--- create data matrices\n",
    "#--- NOTE: below I am transforming panda object to numpy representation with .values\n",
    "#--- Needed to do this for dataloader later on\n",
    "dataset_X = pd.DataFrame(recipe_mat,columns=ing_headline).values #predictors\n",
    "dataset_y = pd.DataFrame(labels_mat,columns=['label']).values #labels\n",
    "X_train_full,X_test,y_train_full,y_test = train_test_split(dataset_X,dataset_y,\n",
    "                                                            test_size=0.2,\n",
    "                                                            random_state = random_state) #train test split\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train_full,y_train_full,\n",
    "                                                test_size=0.25,\n",
    "                                                random_state = random_state) #train val split\n",
    "X_train_len = len(X_train)\n",
    "\n",
    "#--- easier to understand\n",
    "ingredients = ing_headline\n",
    "\n",
    "##--- additionally have cuisines as list\n",
    "#cuisines = []\n",
    "#for n in range(0, 12, 1):\n",
    "#    idx = dataset_y.index[dataset_y.label == n+1]\n",
    "#    cuisines.append(labelName_mat[idx[0]][0].item())\n",
    "\n",
    "#--- how to get index of rows corresponding to one cuisine\n",
    "# dataset_y.index[dataset_y.label == 1]\n",
    "\n",
    "# using this quite often, could have just created a list\n",
    "# with the correspinding indices, will leave it like it is for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--- now data looks like this compared to the table with column names\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- loading required packages\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- adding noise to noise_level% of a recipe, \n",
    "#--- i.e. flip 0's to 1's and the other way arround\n",
    "def add_noise(batch, noise_level=0.3):\n",
    "    with torch.no_grad():\n",
    "        noise = torch.rand(batch.shape) < noise_level\n",
    "        return torch.logical_xor(batch, noise).to(torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- denoising autoencoder\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_shape=709):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.layerE0 = nn.Linear(709, 709) #encoder\n",
    "        self.layerD0 = nn.Linear(709, 709) #decoder\n",
    "    \n",
    "    #--- define forward pass    \n",
    "    def forward(self, x):\n",
    "        # encode \n",
    "        x = nn.functional.relu(self.layerE0(x))\n",
    "        \n",
    "        # decode\n",
    "        x = self.layerD0(x) #apply sigmoid later, see below\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- data loader\n",
    "X_train_tensor = torch.tensor(X_train).to(torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val).to(torch.float32)\n",
    "#--- batch size to be tuned\n",
    "dataloader = torch.utils.data.DataLoader(X_train_tensor, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.8225)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--- just a reminder, average number of recipes\n",
    "X_train_tensor.sum(axis=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- training model\n",
    "\n",
    "#--- since only 10-11 ingredients on average, only add noise to 0.5% of the data,\n",
    "#--- which corresponds to about 3 ingredients changing.\n",
    "#--- this is a hyperparameter to be tuned! (add noise to more or less ingredients)\n",
    "\n",
    "model = AutoEncoder(input_shape=709)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(50):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        noisy_batch = add_noise(batch, noise_level=0.005) #0.5%\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # apply sigmoid as mentioned before\n",
    "        # so that output is between 0 and 1\n",
    "        pred = torch.sigmoid(model(noisy_batch))\n",
    "        \n",
    "        # don't know which loss makes most sense here, \n",
    "        # learning with both\n",
    "        loss = nn.MSELoss()(pred, batch)\n",
    "        #loss = nn.L1Loss()(pred, batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    #print(f\"epoch:{epoch}\\tloss:{loss.item():.04f}\")\n",
    "    \n",
    "    #print(nn.MSELoss()(noisy_batch, batch).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--- just checking if add_noise is working as expected\n",
    "#--- when noise_level=.0, then still identical to original x\n",
    "(add_noise(X_train_tensor, noise_level=.0) == X_train_tensor).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.8278, 3.6033, 6.4118, 2.4321, 7.6689, 4.5361, 4.6442, 4.5032, 3.8904,\n",
       "        3.9517, 6.5478, 8.3725, 4.1392, 6.0618, 4.5452],\n",
       "       grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--- looking at output (before sigmoid) for the ingredients of recipe no. 0\n",
    "#--- which were in recipe (the higher the value, the more the model recommens\n",
    "#--- that particular ingredient)\n",
    "n_recipe = 0\n",
    "model(X_train_tensor)[n_recipe][X_train_tensor[n_recipe]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['basil',\n",
       " 'brown sugar',\n",
       " 'butter',\n",
       " 'dehydrated onion',\n",
       " 'egg',\n",
       " 'flour',\n",
       " 'garlic',\n",
       " 'Italian breadcrumbs',\n",
       " 'lemon',\n",
       " 'mozzarella',\n",
       " 'oregano',\n",
       " 'parmesan cheese',\n",
       " 'pork',\n",
       " 'tomato sauce',\n",
       " 'water']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import compress\n",
    "#--- ingredients of first recipe\n",
    "recipe1 = list(compress(ingredients, [X_train_tensor[n_recipe]==1][0]))\n",
    "recipe1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top k suggestions\n",
      " ['parmesan cheese' 'egg' 'oregano' 'butter' 'tomato sauce' 'basil'\n",
      " 'garlic' 'water' 'flour' 'Italian breadcrumbs' 'pork' 'mozzarella'\n",
      " 'lemon' 'brown sugar' 'dehydrated onion' 'red food coloring' 'prosciutto'\n",
      " 'eggplant' 'onion' 'cottage cheese' 'pesto' 'pepper' 'veal'\n",
      " 'marinara sauce' 'beef' 'ricotta cheese' 'garlic powder' 'salt'\n",
      " 'tomato paste' 'Italian salad dressing' 'olive oil' 'parsley'\n",
      " 'white bread' 'breadcrumb' 'milk' 'pasta sauce' 'chicken' 'mushroom'\n",
      " 'garlic salt' 'greens']\n",
      "\n",
      "top suggestions which are not in recipe\n",
      " ['red food coloring' 'prosciutto' 'eggplant' 'onion' 'cottage cheese'\n",
      " 'pesto' 'pepper' 'veal' 'marinara sauce' 'beef' 'ricotta cheese'\n",
      " 'garlic powder' 'salt' 'tomato paste' 'Italian salad dressing'\n",
      " 'olive oil' 'parsley' 'white bread' 'breadcrumb' 'milk' 'pasta sauce'\n",
      " 'chicken' 'mushroom' 'garlic salt' 'greens']\n",
      "\n",
      "ingredients in original recipe that do not appear in recommendations\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "#--- \n",
    "#torch.argmax(model(X_train_tensor)[0])\n",
    "#ingredients[[torch.topk(model(X_train_tensor)[0], 10).indices][0].numpy()]\n",
    "#[torch.topk(model(X_train_tensor)[0], 10).indices][0].numpy()\n",
    "\n",
    "#--- needed to convert ingredients to np.array\n",
    "arr_ingredients = np.asarray(ingredients)\n",
    "#--- top k recommendations (hopefully including all ingredients from recipe)\n",
    "k = 40\n",
    "topk_suggestions = arr_ingredients[[torch.topk(model(X_train_tensor)[n_recipe], k).indices][0].numpy()]\n",
    "print(\"top k suggestions\\n\", topk_suggestions)\n",
    "print(\"\\ntop suggestions which are not in recipe\\n\", topk_suggestions[np.isin(topk_suggestions, recipe1)==False])\n",
    "print(\"\\ningredients in original recipe that do not appear in recommendations\\n\", \n",
    "      np.setdiff1d(recipe1, topk_suggestions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['parmesan cheese'], dtype='<U30')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(ingredients)[[torch.topk(model(X_train_tensor)[0], 1).indices][0].numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train_tensor[0]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(X_train_tensor)[0][X_train_tensor[0]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(X_val_tensor)[0][X_val_tensor[0]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
